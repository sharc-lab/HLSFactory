{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "372Zu6Ast0yv",
    "outputId": "bf8a0b33-f534-4649-9638-26f83c13eb38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-YOLOv4'...\n",
      "remote: Enumerating objects: 1049, done.\u001b[K\n",
      "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 1049 (delta 2), reused 0 (delta 0), pack-reused 1043\u001b[K\n",
      "Receiving objects: 100% (1049/1049), 2.39 MiB | 8.68 MiB/s, done.\n",
      "Resolving deltas: 100% (644/644), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Tianxiaomo/pytorch-YOLOv4.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rINKktjZuVVj",
    "outputId": "29357ced-b41d-4c18-af5b-b0911968fd48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "pytorch-YOLOv4\tsample_data\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_U93WsWLuplQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"pytorch-YOLOv4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22I3jcgh6Hvr"
   },
   "outputs": [],
   "source": [
    "from tool.darknet2pytorch import Darknet\n",
    "import torch\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAtShnkFLr2x"
   },
   "outputs": [],
   "source": [
    "m = Darknet(\"cfg/yolov4-tiny.cfg\")\n",
    "m.load_weights(\"yolov4-tiny.weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4JxSdqNLXdO",
    "outputId": "a95a3761-9145-4133-8ff2-8bee5d2d0137"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFh8adeqYi5X"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"data/dog.jpg\")\n",
    "sized = cv2.resize(img, (m.width, m.height))\n",
    "sized = cv2.cvtColor(sized, cv2.COLOR_BGR2RGB)\n",
    "img = torch.from_numpy(sized.transpose(2, 0, 1)).float().div(255.0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJnH6dVOYlcg",
    "outputId": "0c68bbb9-496a-437f-d90f-0a848269d611"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (leaky2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_block = m.models[0]\n",
    "first_block\n",
    "second_block = m.models[1]\n",
    "second_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeSHex-IZmD7"
   },
   "outputs": [],
   "source": [
    "def save_to_file(path, data):\n",
    "    print(f\"Writing data with shape {data.shape} to file {path}\")\n",
    "    with open(path, \"wb\") as f:\n",
    "        data.tofile(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWGWcmpGNtI5"
   },
   "outputs": [],
   "source": [
    "def fuse_conv_and_bn(conv, bn):\n",
    "    #\n",
    "    # init\n",
    "    fusedconv = torch.nn.Conv2d(\n",
    "        conv.in_channels,\n",
    "        conv.out_channels,\n",
    "        kernel_size=conv.kernel_size,\n",
    "        stride=conv.stride,\n",
    "        padding=conv.padding,\n",
    "        bias=True,\n",
    "    )\n",
    "    #\n",
    "    # prepare filters\n",
    "    w_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "    w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps + bn.running_var)))\n",
    "    # fusedconv.weight.copy_( torch.mm(w_bn, w_conv).view(fusedconv.weight.size()) )\n",
    "    new_weight = torch.mm(w_bn, w_conv).view(fusedconv.weight.size())\n",
    "    fusedconv.weight = torch.nn.Parameter(new_weight)\n",
    "    #\n",
    "    # prepare spatial bias\n",
    "    if conv.bias is not None:\n",
    "        b_conv = conv.bias\n",
    "    else:\n",
    "        b_conv = torch.zeros(conv.weight.size(0))\n",
    "    b_bn = bn.bias - bn.weight.mul(bn.running_mean).div(\n",
    "        torch.sqrt(bn.running_var + bn.eps)\n",
    "    )\n",
    "    # fusedconv.bias.copy_( torch.matmul(w_bn, b_conv) + b_bn )\n",
    "    new_bias = torch.matmul(w_bn, b_conv) + b_bn\n",
    "    fusedconv.bias = torch.nn.Parameter(new_bias)\n",
    "    #\n",
    "    # we're done\n",
    "    return fusedconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "esqsZxIJELNR"
   },
   "outputs": [],
   "source": [
    "conv_layer1 = first_block[0]\n",
    "bn1 = first_block[1]\n",
    "leaky1 = first_block[2]\n",
    "bn1.bias\n",
    "conv_layer2 = second_block[0]\n",
    "bn2 = second_block[1]\n",
    "leaky2 = second_block[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_mmXR5XdmNK",
    "outputId": "d62c764d-1445-4b94-9836-ac19a70666b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data with shape (32,) to file ./bin/batchnorm_weight.bin\n"
     ]
    }
   ],
   "source": [
    "batchnorm_weight_name = \"./bin/batchnorm_weight.bin\"\n",
    "batchnorm_layer = first_block[1]\n",
    "save_to_file(batchnorm_weight_name, batchnorm_layer.weight.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b82ZcHT2Op4f",
    "outputId": "a598ddb9-35c0-4611-a65d-6ca3e2d7cdb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data with shape (32,) to file ./bin/batchnorm_bias.bin\n"
     ]
    }
   ],
   "source": [
    "batchnorm_bias_name = \"./bin/batchnorm_bias.bin\"\n",
    "batchnorm_layer = first_block[1]\n",
    "save_to_file(batchnorm_bias_name, batchnorm_layer.bias.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afnAm65IUGGN"
   },
   "outputs": [],
   "source": [
    "EPS = bn1.eps\n",
    "bn_factor = torch.div(bn1.weight, torch.sqrt(bn1.running_var + EPS)).view(-1, 1, 1, 1)\n",
    "fused_weight = torch.mul(conv_layer1.weight, bn_factor)\n",
    "fused_bias = bn1.bias - torch.div(\n",
    "    torch.mul(bn1.weight, bn1.running_mean), torch.sqrt(bn1.running_var + EPS)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7NqbEe9WdNg",
    "outputId": "ae18f1d9-552f-40f3-9053-338363425e79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data with shape (32,) to file ../fused_bias.bin\n",
      "Writing data with shape (32, 3, 3, 3) to file ../fused_weight.bin\n"
     ]
    }
   ],
   "source": [
    "fused_bias_name = \"../fused_bias.bin\"\n",
    "bias_l1 = fused_bias\n",
    "save_to_file(fused_bias_name, bias_l1.data.numpy())\n",
    "\n",
    "fused_weight_name = \"../fused_weight.bin\"\n",
    "weight_l1 = fused_weight\n",
    "save_to_file(fused_weight_name, weight_l1.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQc2KCrsImZ6",
    "outputId": "0bfc9e4e-4b77-4ab4-d4a5-d749cb4672d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_conv = fuse_conv_and_bn(conv_layer1, bn1)\n",
    "fused_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_dDBF-zRFuP",
    "outputId": "e7c01888-2a4d-4572-a675-ad9e9a956820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data with shape (32,) to file ../conv_bias.bin\n"
     ]
    }
   ],
   "source": [
    "conv_layer_bias_name = \"../conv_bias.bin\"\n",
    "bias_l1 = fused_conv.bias\n",
    "save_to_file(conv_layer_bias_name, bias_l1.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjnXOYM2XxM6",
    "outputId": "419fc136-ba3e-4a33-9ac7-e60f2b39d02b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data with shape (32, 3, 3, 3) to file ../conv_weight_bn.bin\n"
     ]
    }
   ],
   "source": [
    "conv_layer_mod_wts_name = \"../conv_weight_bn.bin\"\n",
    "conv_l1_wts_bn = fused_conv.weight\n",
    "save_to_file(conv_layer_mod_wts_name, conv_l1_wts_bn.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkkujkRfrnXi"
   },
   "outputs": [],
   "source": [
    "# Original output\n",
    "conv_layer = first_block[0]\n",
    "conv_output = conv_layer(img)\n",
    "batchnorm_layer = first_block[1]\n",
    "batchnorm_output = batchnorm_layer(conv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrUbn3RQtMyW"
   },
   "outputs": [],
   "source": [
    "# Fused conv output\n",
    "fused_output = fused_conv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BFSdl0w0uS5F",
    "outputId": "03ba82ad-6aeb-47a8-b7e1-f8fc8bfc7213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 0.19199745\n"
     ]
    }
   ],
   "source": [
    "net = torch.nn.Sequential(conv_layer1, bn1)\n",
    "y1 = net.forward(img)\n",
    "y2 = fused_conv.forward(img)\n",
    "d = (y1 - y2).norm().div(y1.norm()).item()\n",
    "print(\"error: %.8f\" % d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyfwMFJFd87o"
   },
   "source": [
    "# **Second Layer Parameters Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOFO8RZjeGzm",
    "outputId": "8e4e2830-d4fc-4860-bab5-4e9d73819f14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (leaky2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_block = m.models[1]\n",
    "second_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-NLMqEIeQN8"
   },
   "outputs": [],
   "source": [
    "conv_layer2 = second_block[0]\n",
    "bn2 = second_block[1]\n",
    "leaky2 = second_block[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YjUD2KYekPx",
    "outputId": "fbda3770-e762-4d16-f3de-95f7cc25f228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data with shape (64, 32, 3, 3) to file ./bin/conv_weight2.bin\n"
     ]
    }
   ],
   "source": [
    "conv_layer_weight_name2 = \"./bin/conv_weight2.bin\"\n",
    "save_to_file(conv_layer_weight_name2, conv_layer2.weight.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HsCP5hDgKb9"
   },
   "source": [
    "Output of first layer is input to second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmX3ChVKgP6s"
   },
   "outputs": [],
   "source": [
    "out1_conv = conv_layer1(img)\n",
    "out1_batch = bn1(out1_conv)\n",
    "output_layer1 = leaky1(out1_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87WiDfDwhE3j",
    "outputId": "6c50616f-cc1e-4ace-cd68-b0597ab96a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data with shape (32, 208, 208) to file ./bin/conv_input2.bin\n"
     ]
    }
   ],
   "source": [
    "# write the array to a binary file\n",
    "input_to_second_name = \"./bin/conv_input2.bin\"\n",
    "save_to_file(input_to_second_name, output_layer1[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u3WGb5wMiHU4",
    "outputId": "66343f34-0ede-4cd6-add8-8219c43e7751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data with shape (64,) to file ./bin/batchnorm_weight2.bin\n"
     ]
    }
   ],
   "source": [
    "batchnorm_weight_name2 = \"./bin/batchnorm_weight2.bin\"\n",
    "\n",
    "save_to_file(batchnorm_weight_name2, bn2.weight.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBEal6bZigct",
    "outputId": "63674276-7e9a-496b-a66b-d39d9efcfdb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data with shape (64,) to file ./bin/batchnorm_bias2.bin\n"
     ]
    }
   ],
   "source": [
    "batchnorm_bias_name2 = \"./bin/batchnorm_bias2.bin\"\n",
    "\n",
    "save_to_file(batchnorm_bias_name2, bn2.bias.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNU21RjHizXB"
   },
   "outputs": [],
   "source": [
    "conv_output2 = conv_layer2(output_layer1)\n",
    "batchnorm_output2 = bn2(conv_output2)\n",
    "output_layer2 = leaky2(batchnorm_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVqxvKy8jlTS",
    "outputId": "1c01eb9e-8ae8-4829-ed0a-62a2401ff1ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data with shape (64, 104, 104) to file ./bin/conv_output2.bin\n"
     ]
    }
   ],
   "source": [
    "conv_layer_output_name2 = \"./bin/conv_output2.bin\"\n",
    "\n",
    "save_to_file(conv_layer_output_name2, conv_output2[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVo8oO84j_Xt",
    "outputId": "4c93a14e-6517-4678-812b-529581837d58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data with shape (64, 104, 104) to file ./bin/batchnorm_output2.bin\n"
     ]
    }
   ],
   "source": [
    "batchnorm_layer_output_name2 = \"./bin/batchnorm_output2.bin\"\n",
    "\n",
    "save_to_file(batchnorm_layer_output_name2, batchnorm_output2[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QM5tJg1ukK-x",
    "outputId": "c28edbec-6e0c-4798-f80c-e342dc7aeee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data with shape (64, 104, 104) to file ./bin/relu_output2.bin\n"
     ]
    }
   ],
   "source": [
    "relu_layer_output_name2 = \"./bin/relu_output2.bin\"\n",
    "\n",
    "save_to_file(relu_layer_output_name2, output_layer2[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZID7tYD7evfa"
   },
   "source": [
    "TRYING OUT FUSING FROM SIBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rsTTzotLez_d",
    "outputId": "1d0024f7-423f-496e-98a4-f8cafcee4356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      ")\n",
      "Layer 0 feature map printed to ../conv1.bin\n",
      "Layer 1 feature map printed to ../bn1.bin\n",
      "Layer 2 feature map printed to ../leaky1.bin\n",
      "Fused weights of 1 printed to file ../fused_conv1_bn1_weights.bin\n",
      "Fused biases of 1 printed to file ../fused_conv1_bn1_bias.bin\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "write_layer_outputs_to_file = True\n",
    "write_layer_params_to_file = True\n",
    "\n",
    "features = {}\n",
    "\n",
    "\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "\n",
    "    return hook\n",
    "\n",
    "\n",
    "model = m.models[0]  # Change the model numbers here. This is the first layer now\n",
    "model.eval()\n",
    "print(model)\n",
    "\n",
    "inp = torch.ones(1, 3, 736, 1280)\n",
    "\n",
    "raw_layers = []\n",
    "for layer in model.named_modules():\n",
    "    raw_layers.append(layer[0])\n",
    "\n",
    "leaf_layers = []\n",
    "for i in range(1, len(raw_layers) - 1):\n",
    "    curr_layer = raw_layers[i]\n",
    "    next_layer = raw_layers[i + 1]\n",
    "    if next_layer[: len(curr_layer) + 1] != curr_layer + \".\":\n",
    "        leaf_layers.append(curr_layer)\n",
    "leaf_layers.append(next_layer)\n",
    "\n",
    "layers = []\n",
    "for i in range(len(leaf_layers)):\n",
    "    layers.append(re.sub(r\"\\.(\\d)\", r\"[\\1]\", leaf_layers[i]))\n",
    "\n",
    "for i in range(len(layers)):\n",
    "    layer = layers[i]\n",
    "    layer_hook = (\n",
    "        \"model.\" + layer + \".register_forward_hook(get_features('\" + layer + \"'))\"\n",
    "    )\n",
    "    exec(layer_hook)\n",
    "\n",
    "# Run inference\n",
    "outp = model(inp)\n",
    "\n",
    "EPS = 10**-5  # constant\n",
    "\n",
    "if write_layer_outputs_to_file:\n",
    "    # Write layer outputs\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i]\n",
    "        if layer in features.keys():\n",
    "            layer_name = layer.replace(\"].\", \"_\")\n",
    "            layer_name = layer_name.replace(\"[\", \"_\")\n",
    "            layer_name = layer_name.replace(\"]\", \"\")\n",
    "            filename = \"../\" + layer_name + \".bin\"\n",
    "            with open(filename, \"wb\") as f:\n",
    "                features[layer].cpu().numpy().tofile(f)\n",
    "            print(\"Layer \" + str(i) + \" feature map printed to \" + filename)\n",
    "\n",
    "if write_layer_params_to_file:\n",
    "    # Write layer params\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i]\n",
    "        if \"conv\" in layer or \"downsample[0]\" in layer:\n",
    "            conv_layer_name = layer.replace(\"].\", \"_\")\n",
    "            conv_layer_name = conv_layer_name.replace(\"[\", \"_\")\n",
    "            conv_layer_name = conv_layer_name.replace(\"]\", \"\")\n",
    "\n",
    "            conv_param_name = layer.replace(\"[\", \".\")\n",
    "            conv_param_name = conv_param_name.replace(\"]\", \"\")\n",
    "\n",
    "            conv_weight = model.state_dict()[conv_param_name + \".weight\"]\n",
    "\n",
    "        if \"bn\" in layer or \"downsample[1]\" in layer:\n",
    "            bn_layer_name = layer.replace(\"].\", \"_\")\n",
    "            bn_layer_name = bn_layer_name.replace(\"[\", \"_\")\n",
    "            bn_layer_name = bn_layer_name.replace(\"]\", \"\")\n",
    "\n",
    "            bn_param_name = layer.replace(\"[\", \".\")\n",
    "            bn_param_name = bn_param_name.replace(\"]\", \"\")\n",
    "\n",
    "            bn_weight = model.state_dict()[bn_param_name + \".weight\"]\n",
    "            bn_bias = model.state_dict()[bn_param_name + \".bias\"]\n",
    "            bn_mean = model.state_dict()[bn_param_name + \".running_mean\"]\n",
    "            bn_var = model.state_dict()[bn_param_name + \".running_var\"]\n",
    "\n",
    "            bn_factor = torch.div(bn_weight, torch.sqrt(bn_var + EPS)).view(-1, 1, 1, 1)\n",
    "            fused_weight = torch.mul(conv_weight, bn_factor)\n",
    "            fused_bias = bn_bias - torch.div(\n",
    "                torch.mul(bn_weight, bn_mean), torch.sqrt(bn_var + EPS)\n",
    "            )\n",
    "\n",
    "            if \"downsample\" in bn_layer_name:\n",
    "                layer_number = \"0\"\n",
    "                layer_prefix = bn_layer_name[0 : bn_layer_name.find(\"downsample\")]\n",
    "            else:\n",
    "                layer_number = conv_layer_name[-1]\n",
    "                layer_prefix = bn_layer_name[0 : bn_layer_name.find(\"bn\")]\n",
    "\n",
    "            weights_filename = (\n",
    "                \"../fused_\"\n",
    "                + layer_prefix\n",
    "                + \"conv\"\n",
    "                + layer_number\n",
    "                + \"_bn\"\n",
    "                + layer_number\n",
    "                + \"_weights.bin\"\n",
    "            )  # This gives the bin for weights\n",
    "            bias_filename = (\n",
    "                \"../fused_\"\n",
    "                + layer_prefix\n",
    "                + \"conv\"\n",
    "                + layer_number\n",
    "                + \"_bn\"\n",
    "                + layer_number\n",
    "                + \"_bias.bin\"\n",
    "            )  # This gives the bin for bias\n",
    "\n",
    "            with open(weights_filename, \"wb\") as f:\n",
    "                fused_weight.detach().numpy().tofile(f)\n",
    "            print(\n",
    "                \"Fused weights of \"\n",
    "                + layer_prefix\n",
    "                + layer_number\n",
    "                + \" printed to file \"\n",
    "                + weights_filename\n",
    "            )\n",
    "\n",
    "            with open(bias_filename, \"wb\") as f:\n",
    "                fused_bias.detach().numpy().tofile(f)\n",
    "            print(\n",
    "                \"Fused biases of \"\n",
    "                + layer_prefix\n",
    "                + layer_number\n",
    "                + \" printed to file \"\n",
    "                + bias_filename\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}